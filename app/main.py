import streamlit as st
import requests
import json
from models import insert_text_file_into_chroma

API_URL = "http://127.0.0.1:8000/rag"

def chat_with_bot(query: str, model: str) -> dict:
    payload = {"query": query, "model": model}
    try:
        response = requests.post(API_URL, json=payload)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"response": f"Erreur lors de la connexion √† l'API : {str(e)}", "context": []}

st.set_page_config(page_title="SH Chatbot - Recherche Augment√©e", layout="wide")
st.title("ü§ñ SH Chatbot - Recherche Augment√©e")
st.markdown("Posez vos questions et enrichissez la base de connaissances avec vos propres fichiers !")

if "history" not in st.session_state:
    st.session_state.history = []

col1, col2, col3 = st.columns([1, 3, 1])

with col1:
    st.subheader("üìú Historique")
    if not st.session_state.history:
        st.info("Aucune conversation pour le moment.")
    else:
        for chat in st.session_state.history:
            with st.expander(f"{chat['query'][:30]}...", expanded=False):
                st.markdown(f"**Vous** : {chat['query']}")
                st.markdown(f"**Bot** : {chat['response']}")
                if "context" in chat:
                    st.markdown("**Contexte** :")
                    for doc in chat["context"]:
                        st.write(f"- {doc['text'][:50]}... ({doc['distance']:.2f})")
            st.markdown("---")

with col2:
    st.subheader("üí¨ Conversation en cours")
    query = st.text_area("Entrez votre question :", height=150, placeholder="Ex. : Quelles sont les dates importantes ?")
    if st.button("üöÄ Envoyer", type="primary") and query.strip():
        with st.spinner("R√©ponse en cours de g√©n√©ration..."):
            result = chat_with_bot(query, st.session_state.get("model", "qwen2:1.5b"))
            response = result.get("response", "Erreur : aucune r√©ponse re√ßue")
            context = result.get("context", [])
            st.session_state.history.append({"query": query, "response": response, "context": context})
            st.markdown("### R√©ponse :")
            st.write(response)
            with st.expander("Voir le contexte utilis√©", expanded=False):
                if context:
                    for doc in context:
                        st.write(f"- {doc['text'][:100]}... (Score: {doc['distance']:.2f})")
                else:
                    st.write("Aucun contexte disponible.")
    elif query.strip() == "":
        st.warning("Veuillez entrer une question valide.")

with col3:
    st.subheader("‚öôÔ∏è Param√®tres")
    models = ["qwen2.5:3b", "llama3.2:latest", "deepseek-r1:1.5b", "qwen2:1.5b"]
    selected_model = st.selectbox("Mod√®le :", models, help="Choisissez le mod√®le de langage.")
    st.session_state.model = selected_model
    if st.button("üóëÔ∏è R√©initialiser"):
        st.session_state.history = []
        st.success("Historique r√©initialis√© !")
    st.markdown("---")
    st.subheader("üìÇ Importer un fichier")
    uploaded_file = st.file_uploader("Ajoutez un fichier texte (.txt)", type=["txt"])
    if uploaded_file is not None:
        file_path = f"temp_{uploaded_file.name}"
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        try:
            result = insert_text_file_into_chroma(file_path)
            if result["success"]:
                st.success(f"{result['message']} ({result['chunks_created']} chunks cr√©√©s)")
            else:
                st.error(result["message"])
        except Exception as e:
            st.error(f"Erreur : {str(e)}")
        finally:
            if os.path.exists(file_path):
                os.remove(file_path)

st.markdown("---")
st.caption("RAG est r√©alis√©e par H. Sami  ‚Ä¢ Date : 23 f√©vrier 2025")